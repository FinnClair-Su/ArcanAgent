"""
Markdown Parser
Parses markdown files with YAML frontmatter and extracts links
"""

import re
import yaml
import logging
from typing import Dict, List, Any, Tuple, Optional


logger = logging.getLogger(__name__)


class MarkdownParser:
    \"\"\"Parser for markdown files with YAML frontmatter\"\"\"\n    \n    def __init__(self):\n        # Regex patterns\n        self.frontmatter_pattern = re.compile(\n            r'^---\\s*\\n(.*?)\\n---\\s*\\n(.*)$', \n            re.DOTALL | re.MULTILINE\n        )\n        self.link_pattern = re.compile(r'\\[\\[([^\\]]+)\\]\\]')\n        self.tag_pattern = re.compile(r'#([\\w\\-_]+)')\n        self.heading_pattern = re.compile(r'^(#+)\\s+(.+)$', re.MULTILINE)\n    \n    async def parse_markdown(self, content: str) -> Dict[str, Any]:\n        \"\"\"Parse markdown content and extract all components\"\"\"\n        \n        # Extract frontmatter and content\n        frontmatter, body = self._extract_frontmatter(content)\n        \n        # Parse content components\n        links = self._extract_links(body)\n        tags = self._extract_tags(body)\n        headings = self._extract_headings(body)\n        \n        return {\n            \"frontmatter\": frontmatter,\n            \"content\": body,\n            \"links\": links,\n            \"tags\": tags,\n            \"headings\": headings,\n            \"word_count\": len(body.split()),\n            \"character_count\": len(body)\n        }\n    \n    def _extract_frontmatter(self, content: str) -> Tuple[Dict[str, Any], str]:\n        \"\"\"Extract YAML frontmatter from markdown\"\"\"\n        \n        match = self.frontmatter_pattern.match(content)\n        \n        if match:\n            yaml_content = match.group(1)\n            body_content = match.group(2)\n            \n            try:\n                frontmatter = yaml.safe_load(yaml_content) or {}\n            except yaml.YAMLError as e:\n                logger.warning(f\"Failed to parse YAML frontmatter: {e}\")\n                frontmatter = {}\n            \n            return frontmatter, body_content\n        else:\n            # No frontmatter found\n            return {}, content\n    \n    def _extract_links(self, content: str) -> List[Dict[str, str]]:\n        \"\"\"Extract all [[wiki-style]] links from content\"\"\"\n        \n        links = []\n        \n        for match in self.link_pattern.finditer(content):\n            link_content = match.group(1)\n            \n            # Handle alias links [[target|alias]]\n            if '|' in link_content:\n                target, alias = link_content.split('|', 1)\n                links.append({\n                    \"target\": target.strip(),\n                    \"alias\": alias.strip(),\n                    \"display\": alias.strip(),\n                    \"position\": match.span(),\n                    \"raw\": match.group(0)\n                })\n            else:\n                target = link_content.strip()\n                links.append({\n                    \"target\": target,\n                    \"alias\": None,\n                    \"display\": target,\n                    \"position\": match.span(),\n                    \"raw\": match.group(0)\n                })\n        \n        return links\n    \n    def _extract_tags(self, content: str) -> List[str]:\n        \"\"\"Extract hashtags from content\"\"\"\n        \n        tags = []\n        \n        for match in self.tag_pattern.finditer(content):\n            tag = match.group(1)\n            if tag not in tags:  # Avoid duplicates\n                tags.append(tag)\n        \n        return tags\n    \n    def _extract_headings(self, content: str) -> List[Dict[str, Any]]:\n        \"\"\"Extract all headings from content\"\"\"\n        \n        headings = []\n        \n        for match in self.heading_pattern.finditer(content):\n            level = len(match.group(1))  # Number of # characters\n            text = match.group(2).strip()\n            \n            headings.append({\n                \"level\": level,\n                \"text\": text,\n                \"position\": match.span(),\n                \"anchor\": self._generate_anchor(text)\n            })\n        \n        return headings\n    \n    def _generate_anchor(self, heading_text: str) -> str:\n        \"\"\"Generate URL-safe anchor from heading text\"\"\"\n        \n        # Convert to lowercase and replace spaces with hyphens\n        anchor = heading_text.lower()\n        anchor = re.sub(r'[^\\w\\s-]', '', anchor)  # Remove special chars\n        anchor = re.sub(r'[-\\s]+', '-', anchor)  # Replace spaces with hyphens\n        anchor = anchor.strip('-')\n        \n        return anchor\n    \n    async def build_frontmatter(self, metadata: Dict[str, Any]) -> str:\n        \"\"\"Build YAML frontmatter from metadata\"\"\"\n        \n        if not metadata:\n            return \"\"\n        \n        try:\n            yaml_content = yaml.dump(\n                metadata, \n                default_flow_style=False, \n                allow_unicode=True,\n                sort_keys=False\n            )\n            return f\"---\\n{yaml_content}---\\n\"\n        except Exception as e:\n            logger.error(f\"Failed to build YAML frontmatter: {e}\")\n            return \"\"\n    \n    async def build_markdown(self, frontmatter: Dict[str, Any], content: str) -> str:\n        \"\"\"Build complete markdown with frontmatter\"\"\"\n        \n        fm_str = await self.build_frontmatter(frontmatter)\n        \n        if fm_str:\n            return f\"{fm_str}\\n{content}\"\n        else:\n            return content\n    \n    async def update_frontmatter_field(self, content: str, field: str, value: Any) -> str:\n        \"\"\"Update a specific field in the frontmatter\"\"\"\n        \n        frontmatter, body = self._extract_frontmatter(content)\n        frontmatter[field] = value\n        \n        return await self.build_markdown(frontmatter, body)\n    \n    async def add_link_to_content(self, content: str, target: str, alias: str = None, position: str = \"end\") -> str:\n        \"\"\"Add a new link to markdown content\"\"\"\n        \n        if alias:\n            link_text = f\"[[{target}|{alias}]]\"\n        else:\n            link_text = f\"[[{target}]]\"\n        \n        if position == \"end\":\n            if content.strip():\n                return f\"{content}\\n\\n{link_text}\"\n            else:\n                return link_text\n        elif position == \"start\":\n            if content.strip():\n                return f\"{link_text}\\n\\n{content}\"\n            else:\n                return link_text\n        else:\n            # Insert at specific position (not implemented)\n            return f\"{content} {link_text}\"\n    \n    async def remove_link_from_content(self, content: str, target: str) -> str:\n        \"\"\"Remove all links to a specific target\"\"\"\n        \n        # Remove both regular and alias links\n        patterns = [\n            f\"\\\\[\\\\[{re.escape(target)}\\\\]\\\\]\",  # [[target]]\n            f\"\\\\[\\\\[{re.escape(target)}\\\\|[^\\\\]]+\\\\]\\\\]\"  # [[target|alias]]\n        ]\n        \n        for pattern in patterns:\n            content = re.sub(pattern, \"\", content)\n        \n        # Clean up extra whitespace\n        content = re.sub(r'\\n\\s*\\n\\s*\\n', '\\n\\n', content)  # Multiple newlines\n        content = re.sub(r' +', ' ', content)  # Multiple spaces\n        \n        return content.strip()\n    \n    async def extract_summary(self, content: str, max_words: int = 50) -> str:\n        \"\"\"Extract a summary from the content\"\"\"\n        \n        # Remove markdown formatting\n        clean_content = self._clean_markdown(content)\n        \n        # Split into words and take first N words\n        words = clean_content.split()\n        summary_words = words[:max_words]\n        \n        summary = ' '.join(summary_words)\n        \n        if len(words) > max_words:\n            summary += \"...\"\n        \n        return summary\n    \n    def _clean_markdown(self, content: str) -> str:\n        \"\"\"Remove markdown formatting for plain text extraction\"\"\"\n        \n        # Remove links\n        content = re.sub(r'\\[\\[([^\\]]+)\\]\\]', r'\\1', content)\n        \n        # Remove bold/italic\n        content = re.sub(r'\\*\\*([^*]+)\\*\\*', r'\\1', content)\n        content = re.sub(r'\\*([^*]+)\\*', r'\\1', content)\n        \n        # Remove headings\n        content = re.sub(r'^#+\\s+', '', content, flags=re.MULTILINE)\n        \n        # Remove code blocks\n        content = re.sub(r'```[^`]*```', '', content, flags=re.DOTALL)\n        content = re.sub(r'`([^`]+)`', r'\\1', content)\n        \n        # Remove extra whitespace\n        content = re.sub(r'\\s+', ' ', content)\n        \n        return content.strip()\n    \n    async def validate_markdown(self, content: str) -> Dict[str, Any]:\n        \"\"\"Validate markdown content and return issues\"\"\"\n        \n        issues = []\n        warnings = []\n        \n        try:\n            parsed = await self.parse_markdown(content)\n            \n            # Check frontmatter\n            frontmatter = parsed[\"frontmatter\"]\n            \n            if not frontmatter.get(\"title\"):\n                warnings.append(\"No title in frontmatter\")\n            \n            if not frontmatter.get(\"created\"):\n                warnings.append(\"No created date in frontmatter\")\n            \n            # Check for broken link syntax\n            broken_links = re.findall(r'\\[\\[[^\\]]*$', content)  # Unclosed links\n            if broken_links:\n                issues.append(f\"Found {len(broken_links)} unclosed links\")\n            \n            # Check for empty headings\n            empty_headings = re.findall(r'^#+\\s*$', content, re.MULTILINE)\n            if empty_headings:\n                warnings.append(f\"Found {len(empty_headings)} empty headings\")\n            \n        except Exception as e:\n            issues.append(f\"Parse error: {str(e)}\")\n        \n        return {\n            \"valid\": len(issues) == 0,\n            \"issues\": issues,\n            \"warnings\": warnings\n        }"