"""
Link Graph Manager
Builds and manages the knowledge graph from bidirectional links
"""

import logging
from typing import Dict, List, Set, Tuple, Optional, Any
from collections import defaultdict, deque
import heapq
import networkx as nx


logger = logging.getLogger(__name__)


class LinkGraph:
    \"\"\"Manages the knowledge graph structure and provides graph algorithms\"\"\"\n    \n    def __init__(self):\n        # Use NetworkX for advanced graph algorithms\n        self.graph = nx.DiGraph()  # Directed graph for link relationships\n        \n        # Fast lookup structures\n        self.node_data: Dict[str, Dict[str, Any]] = {}  # node_id -> metadata\n        self.edge_weights: Dict[Tuple[str, str], float] = {}  # edge -> weight\n        \n        # Cache for expensive computations\n        self._centrality_cache: Dict[str, Dict[str, float]] = {}\n        self._shortest_paths_cache: Dict[Tuple[str, str], List[str]] = {}\n        self._cache_dirty = True\n    \n    async def build_graph(self, note_index: Dict[str, Dict[str, Any]]):\n        \"\"\"Build the complete graph from note index\"\"\"\n        \n        logger.info(\"Building link graph...\")\n        \n        # Clear existing graph\n        self.graph.clear()\n        self.node_data.clear()\n        self.edge_weights.clear()\n        self._invalidate_cache()\n        \n        # Add all nodes\n        for note_id, note_data in note_index.items():\n            await self.add_note(note_id, note_data)\n        \n        # Add edges based on links\n        for note_id, note_data in note_index.items():\n            links = note_data.get(\"links\", [])\n            for link in links:\n                target_title = link.get(\"target\", \"\")\n                target_id = self._find_note_id_by_title(target_title, note_index)\n                \n                if target_id and target_id != note_id:\n                    await self.add_edge(note_id, target_id)\n        \n        logger.info(f\"Built graph with {self.graph.number_of_nodes()} nodes and {self.graph.number_of_edges()} edges\")\n    \n    def _find_note_id_by_title(self, title: str, note_index: Dict[str, Dict[str, Any]]) -> Optional[str]:\n        \"\"\"Find note ID by title\"\"\"\n        title_lower = title.lower()\n        \n        for note_id, note_data in note_index.items():\n            if note_data.get(\"title\", \"\").lower() == title_lower:\n                return note_id\n        \n        return None\n    \n    async def add_note(self, note_id: str, note_data: Dict[str, Any]):\n        \"\"\"Add or update a note in the graph\"\"\"\n        \n        # Extract relevant metadata\n        metadata = {\n            \"title\": note_data.get(\"title\", \"\"),\n            \"tags\": note_data.get(\"frontmatter\", {}).get(\"tags\", []),\n            \"created\": note_data.get(\"frontmatter\", {}).get(\"created\"),\n            \"updated\": note_data.get(\"frontmatter\", {}).get(\"updated\"),\n            \"word_count\": len(note_data.get(\"content\", \"\").split()),\n            \"importance\": note_data.get(\"frontmatter\", {}).get(\"importance\", 0.5)\n        }\n        \n        self.graph.add_node(note_id, **metadata)\n        self.node_data[note_id] = metadata\n        \n        self._invalidate_cache()\n    \n    async def add_edge(self, source_id: str, target_id: str, weight: float = 1.0):\n        \"\"\"Add an edge between two notes\"\"\"\n        \n        if source_id in self.graph and target_id in self.graph:\n            self.graph.add_edge(source_id, target_id, weight=weight)\n            self.edge_weights[(source_id, target_id)] = weight\n            \n            self._invalidate_cache()\n    \n    async def remove_note(self, note_id: str):\n        \"\"\"Remove a note from the graph\"\"\"\n        \n        if note_id in self.graph:\n            # Remove all edges involving this node\n            edges_to_remove = list(self.graph.in_edges(note_id)) + list(self.graph.out_edges(note_id))\n            \n            for edge in edges_to_remove:\n                if edge in self.edge_weights:\n                    del self.edge_weights[edge]\n            \n            self.graph.remove_node(note_id)\n            \n            if note_id in self.node_data:\n                del self.node_data[note_id]\n            \n            self._invalidate_cache()\n    \n    async def update_note(self, note_id: str, note_data: Dict[str, Any]):\n        \"\"\"Update note metadata in the graph\"\"\"\n        \n        if note_id in self.graph:\n            # Update node attributes\n            metadata = {\n                \"title\": note_data.get(\"title\", \"\"),\n                \"tags\": note_data.get(\"frontmatter\", {}).get(\"tags\", []),\n                \"updated\": note_data.get(\"frontmatter\", {}).get(\"updated\"),\n                \"word_count\": len(note_data.get(\"content\", \"\").split()),\n                \"importance\": note_data.get(\"frontmatter\", {}).get(\"importance\", 0.5)\n            }\n            \n            nx.set_node_attributes(self.graph, {note_id: metadata})\n            self.node_data[note_id].update(metadata)\n            \n            self._invalidate_cache()\n    \n    def _invalidate_cache(self):\n        \"\"\"Invalidate all caches when graph changes\"\"\"\n        self._centrality_cache.clear()\n        self._shortest_paths_cache.clear()\n        self._cache_dirty = True\n    \n    async def find_shortest_path(self, source_id: str, target_id: str) -> Optional[List[str]]:\n        \"\"\"Find shortest path between two notes\"\"\"\n        \n        cache_key = (source_id, target_id)\n        \n        if cache_key in self._shortest_paths_cache:\n            return self._shortest_paths_cache[cache_key]\n        \n        try:\n            path = nx.shortest_path(self.graph, source_id, target_id)\n            self._shortest_paths_cache[cache_key] = path\n            return path\n        except (nx.NetworkXNoPath, nx.NodeNotFound):\n            self._shortest_paths_cache[cache_key] = None\n            return None\n    \n    async def find_all_shortest_paths(self, source_id: str, target_id: str, limit: int = 5) -> List[List[str]]:\n        \"\"\"Find multiple shortest paths between two notes\"\"\"\n        \n        try:\n            paths = list(nx.all_shortest_paths(self.graph, source_id, target_id))\n            return paths[:limit]\n        except (nx.NetworkXNoPath, nx.NodeNotFound):\n            return []\n    \n    async def get_neighbors(self, note_id: str, direction: str = \"both\", distance: int = 1) -> Set[str]:\n        \"\"\"Get neighboring notes within specified distance\"\"\"\n        \n        if note_id not in self.graph:\n            return set()\n        \n        neighbors = set()\n        \n        if direction in [\"out\", \"both\"]:\n            # Outgoing neighbors (notes this note links to)\n            for d in range(1, distance + 1):\n                if d == 1:\n                    neighbors.update(self.graph.successors(note_id))\n                else:\n                    # Multi-hop neighbors\n                    current_level = {note_id}\n                    for _ in range(d):\n                        next_level = set()\n                        for node in current_level:\n                            next_level.update(self.graph.successors(node))\n                        current_level = next_level\n                    neighbors.update(current_level)\n        \n        if direction in [\"in\", \"both\"]:\n            # Incoming neighbors (notes that link to this note)\n            for d in range(1, distance + 1):\n                if d == 1:\n                    neighbors.update(self.graph.predecessors(note_id))\n                else:\n                    # Multi-hop neighbors\n                    current_level = {note_id}\n                    for _ in range(d):\n                        next_level = set()\n                        for node in current_level:\n                            next_level.update(self.graph.predecessors(node))\n                        current_level = next_level\n                    neighbors.update(current_level)\n        \n        # Remove the source node itself\n        neighbors.discard(note_id)\n        \n        return neighbors\n    \n    async def calculate_centrality(self, algorithm: str = \"pagerank\") -> Dict[str, float]:\n        \"\"\"Calculate centrality scores for all nodes\"\"\"\n        \n        if algorithm in self._centrality_cache:\n            return self._centrality_cache[algorithm]\n        \n        try:\n            if algorithm == \"pagerank\":\n                centrality = nx.pagerank(self.graph)\n            elif algorithm == \"betweenness\":\n                centrality = nx.betweenness_centrality(self.graph)\n            elif algorithm == \"closeness\":\n                centrality = nx.closeness_centrality(self.graph)\n            elif algorithm == \"degree\":\n                centrality = dict(self.graph.degree())\n                # Normalize\n                max_degree = max(centrality.values()) if centrality else 1\n                centrality = {k: v / max_degree for k, v in centrality.items()}\n            else:\n                raise ValueError(f\"Unknown centrality algorithm: {algorithm}\")\n            \n            self._centrality_cache[algorithm] = centrality\n            return centrality\n            \n        except Exception as e:\n            logger.error(f\"Error calculating {algorithm} centrality: {e}\")\n            return {}\n    \n    async def find_hub_notes(self, top_k: int = 10) -> List[Tuple[str, float]]:\n        \"\"\"Find the most connected/important notes\"\"\"\n        \n        pagerank_scores = await self.calculate_centrality(\"pagerank\")\n        \n        # Sort by PageRank score\n        hubs = sorted(pagerank_scores.items(), key=lambda x: x[1], reverse=True)\n        \n        return hubs[:top_k]\n    \n    async def find_bridge_notes(self, source_id: str, target_id: str) -> List[str]:\n        \"\"\"Find notes that bridge between two clusters or topics\"\"\"\n        \n        # Find nodes that appear in shortest paths between source and target\n        paths = await self.find_all_shortest_paths(source_id, target_id)\n        \n        bridge_counts = defaultdict(int)\n        \n        for path in paths:\n            for node in path[1:-1]:  # Exclude source and target\n                bridge_counts[node] += 1\n        \n        # Sort by frequency of appearance in paths\n        bridges = sorted(bridge_counts.items(), key=lambda x: x[1], reverse=True)\n        \n        return [node for node, count in bridges]\n    \n    async def get_cluster_around_note(self, note_id: str, max_size: int = 20) -> Set[str]:\n        \"\"\"Get a cluster of related notes around a central note\"\"\"\n        \n        if note_id not in self.graph:\n            return set()\n        \n        cluster = {note_id}\n        \n        # Use BFS to expand the cluster\n        queue = deque([(note_id, 0)])\n        visited = {note_id}\n        \n        while queue and len(cluster) < max_size:\n            current, distance = queue.popleft()\n            \n            # Get neighbors (both directions)\n            neighbors = set(self.graph.successors(current)) | set(self.graph.predecessors(current))\n            \n            for neighbor in neighbors:\n                if neighbor not in visited and len(cluster) < max_size:\n                    cluster.add(neighbor)\n                    visited.add(neighbor)\n                    \n                    # Add to queue for further expansion (limit distance)\n                    if distance < 2:\n                        queue.append((neighbor, distance + 1))\n        \n        return cluster\n    \n    async def analyze_note_importance(self, note_id: str) -> Dict[str, float]:\n        \"\"\"Analyze the importance of a note from multiple perspectives\"\"\"\n        \n        if note_id not in self.graph:\n            return {}\n        \n        # Calculate different centrality measures\n        pagerank = await self.calculate_centrality(\"pagerank\")\n        betweenness = await self.calculate_centrality(\"betweenness\")\n        degree = await self.calculate_centrality(\"degree\")\n        \n        # Local metrics\n        in_degree = self.graph.in_degree(note_id)\n        out_degree = self.graph.out_degree(note_id)\n        \n        return {\n            \"pagerank\": pagerank.get(note_id, 0),\n            \"betweenness\": betweenness.get(note_id, 0),\n            \"degree_centrality\": degree.get(note_id, 0),\n            \"in_degree\": in_degree,\n            \"out_degree\": out_degree,\n            \"total_degree\": in_degree + out_degree\n        }\n    \n    async def get_total_links(self) -> int:\n        \"\"\"Get total number of links in the graph\"\"\"\n        return self.graph.number_of_edges()\n    \n    async def get_graph_statistics(self) -> Dict[str, Any]:\n        \"\"\"Get comprehensive graph statistics\"\"\"\n        \n        # Basic metrics\n        num_nodes = self.graph.number_of_nodes()\n        num_edges = self.graph.number_of_edges()\n        \n        # Density\n        density = nx.density(self.graph) if num_nodes > 1 else 0\n        \n        # Connected components (treat as undirected for this analysis)\n        undirected = self.graph.to_undirected()\n        num_components = nx.number_connected_components(undirected)\n        largest_component_size = len(max(nx.connected_components(undirected), key=len)) if num_components > 0 else 0\n        \n        # Centrality analysis\n        pagerank_scores = await self.calculate_centrality(\"pagerank\")\n        \n        return {\n            \"nodes\": num_nodes,\n            \"edges\": num_edges,\n            \"density\": density,\n            \"average_degree\": (2 * num_edges) / max(num_nodes, 1),\n            \"connected_components\": num_components,\n            \"largest_component_size\": largest_component_size,\n            \"most_important_note\": max(pagerank_scores.items(), key=lambda x: x[1]) if pagerank_scores else None\n        }"